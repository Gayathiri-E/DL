{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJQBg7pF90fMDOwIwCrXY9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gayathiri-E/DL/blob/main/DL_NN_code_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-QWqZ_9RzmN"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array(([1,0,1,0],[1,0,1,1],[0,1,0,1]))"
      ],
      "metadata": {
        "id": "RmNS1FFJSpzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF06KXWhS0uS",
        "outputId": "b4cd96fd-ef15-4420-9d8f-1185bfabb1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 0],\n",
              "       [1, 0, 1, 1],\n",
              "       [0, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=np.array(([1],[0],[1]))\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZSFyEslS5qE",
        "outputId": "68789865-bbeb-4d4b-c0a3-a87ae7c9d264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))"
      ],
      "metadata": {
        "id": "JkgI1GEDTRDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def derivative_sigmoid(x):\n",
        "  return x*(1-x)"
      ],
      "metadata": {
        "id": "Ipl08YebTlwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch=5000\n",
        "lr = 0.1\n",
        "input_neurons=x.shape[1]\n",
        "hidden_neurons=3\n",
        "output_neurons=1"
      ],
      "metadata": {
        "id": "NTgQiZtMTzse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wh = np.random.uniform(size=(input_neurons,hidden_neurons))\n",
        "#uniform--input ku thaguntha mari random ah values ah eduthkum for weights and bias in hidden and output\n",
        "bh = np.random.uniform(size=(1,hidden_neurons))\n",
        "wo = np.random.uniform(size=(hidden_neurons,output_neurons))\n",
        "bo = np.random.uniform(size=(1,output_neurons))"
      ],
      "metadata": {
        "id": "8SCGzy2EUbQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epoch):\n",
        "  #same as single layer perceptron\n",
        "  #forward propogation\n",
        "  hidden_input=np.dot(x,wh)\n",
        "  hidden_input=hidden_input+bh\n",
        "  hidden_activation=sigmoid(hidden_input)\n",
        "  output_layer=np.dot(hidden_activation,wo)\n",
        "  output=sigmoid(output_layer)\n",
        "\n",
        "  #backward propagation\n",
        "  E=y-output\n",
        "  slope_output=derivative_sigmoid(output)\n",
        "  slope_hidden=derivative_sigmoid(hidden_activation)\n",
        "  d_output=E*slope_output\n",
        "  error_hidden=d_output.dot(wo.T)\n",
        "  d_hidden=error_hidden*slope_hidden\n",
        "  wo+=hidden_activation.T.dot(d_output)*lr\n",
        "  bo+=np.sum(d_output,axis=0,keepdims=True)*lr\n",
        "  wh+=x.T.dot(d_hidden)*lr\n",
        "  bh+=np.sum(d_hidden,axis=0,keepdims=True)*lr"
      ],
      "metadata": {
        "id": "meZgG_8cVQLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y02_jSUTY10a",
        "outputId": "eac10fa5-8d57-449f-e302-9a1ff06f3c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.95389792],\n",
              "       [0.06113226],\n",
              "       [0.96703314]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "x = iris.data\n",
        "y = iris.target.reshape(-1, 1)  # Reshape to a column vector\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def derivative_sigmoid(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "epoch = 5000\n",
        "lr = 0.1  # learning_rate\n",
        "input_neurons = x.shape[1]\n",
        "hidden_neurons = 2\n",
        "output_neurons = 1\n",
        "\n",
        "# Initialize weights and biases\n",
        "wh = np.random.uniform(size=(input_neurons, hidden_neurons))\n",
        "bh = np.zeros((1, hidden_neurons))\n",
        "wo = np.random.uniform(size=(hidden_neurons, output_neurons))\n",
        "bo = np.zeros((1, output_neurons))\n",
        "\n",
        "# This coding is the same as Perceptron in Machine Learning\n",
        "for i in range(epoch):\n",
        "    # Forward Propagation\n",
        "    hidden_input = np.dot(x, wh) + bh\n",
        "    hidden_activation = sigmoid(hidden_input)\n",
        "    output_layer = np.dot(hidden_activation, wo) + bo\n",
        "    output = sigmoid(output_layer)\n",
        "\n",
        "    # Backward Propagation\n",
        "    E = y - output  # Error: target - predicted\n",
        "    slope_output = derivative_sigmoid(output)\n",
        "    slope_hidden = derivative_sigmoid(hidden_activation)\n",
        "\n",
        "    d_output = E * slope_output\n",
        "    error_hidden = d_output.dot(wo.T)\n",
        "    d_hidden = error_hidden * slope_hidden\n",
        "\n",
        "    wo += np.dot(hidden_activation.T, d_output) * lr\n",
        "    bo += np.sum(d_output, axis=0, keepdims=True) * lr\n",
        "    wh += np.dot(x.T, d_hidden) * lr\n",
        "    bh += np.sum(d_hidden, axis=0, keepdims=True) * lr"
      ],
      "metadata": {
        "id": "gxoXDgBpec5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "oe4yDQDdeedh",
        "outputId": "1e073f4e-7c79-46eb-eb6d-8ed461f7fdbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546],\n",
              "       [0.999546]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IRIS DATASET"
      ],
      "metadata": {
        "id": "L7ATPQFeeWB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the Iris dataset using datasets library\n",
        "iris = load_iris()\n",
        "iris_data = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])\n",
        "\n",
        "# Map target classes to numerical values\n",
        "class_mapping = {0: 0, 1: 1, 2: 2}\n",
        "iris_data['target'] = iris_data['target'].map(class_mapping)\n",
        "\n",
        "# Extract features and labels\n",
        "X = iris_data.iloc[:, :-1].values\n",
        "y = iris_data.iloc[:, -1].values.reshape(-1, 1)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (optional but recommended)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def derivative_sigmoid(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Define neural network architecture\n",
        "input_neurons = X_train.shape[1]\n",
        "hidden_neurons = 8\n",
        "output_neurons = len(np.unique(y_train))\n",
        "\n",
        "wh = np.random.uniform(size=(input_neurons, hidden_neurons))\n",
        "bh = np.random.uniform(size=(1, hidden_neurons))\n",
        "wo = np.random.uniform(size=(hidden_neurons, output_neurons))\n",
        "bo = np.random.uniform(size=(1, output_neurons))\n",
        "\n",
        "# Training parameters\n",
        "lr = 0.1\n",
        "epochs = 1500\n",
        "\n",
        "# Training the neural network\n",
        "for epoch in range(epochs):\n",
        "    # Forward propagation\n",
        "    hidden_input = np.dot(X_train, wh)\n",
        "    hidden_input += bh\n",
        "    hidden_activation = sigmoid(hidden_input)\n",
        "    output_layer = np.dot(hidden_activation, wo)\n",
        "    output = sigmoid(output_layer)\n",
        "\n",
        "    # Backward propagation\n",
        "    E = y_train - output\n",
        "    slope_output = derivative_sigmoid(output)\n",
        "    slope_hidden = derivative_sigmoid(hidden_activation)\n",
        "    d_output = E * slope_output\n",
        "    error_hidden = d_output.dot(wo.T)\n",
        "    d_hidden = error_hidden * slope_hidden\n",
        "\n",
        "    # Update weights and biases\n",
        "    wo += hidden_activation.T.dot(d_output) * lr\n",
        "    bo += np.sum(d_output, axis=0, keepdims=True) * lr\n",
        "    wh += X_train.T.dot(d_hidden) * lr\n",
        "    bh += np.sum(d_hidden, axis=0, keepdims=True) * lr\n",
        "\n",
        "    # Print mean squared error for every 100 epochs\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        mse = np.mean((y_train - output) ** 2)\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Mean Squared Error: {mse}\")\n",
        "\n",
        "# Testing the neural network\n",
        "hidden_input_test = np.dot(X_test, wh) + bh\n",
        "hidden_activation_test = sigmoid(hidden_input_test)\n",
        "output_layer_test = np.dot(hidden_activation_test, wo) + bo\n",
        "output_test = sigmoid(output_layer_test)\n",
        "\n",
        "# Convert output to predicted labels\n",
        "y_pred = np.argmax(output_test, axis=1)\n",
        "\n",
        "# Convert one-hot encoded predictions to class labels\n",
        "y_pred = np.argmax(output_test, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-kY-2vfeRNd",
        "outputId": "fdc7e016-b8b0-4bc1-dc99-9b6f139883af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/1500, Mean Squared Error: 0.3257287227226545\n",
            "Epoch 200/1500, Mean Squared Error: 0.3253195907489713\n",
            "Epoch 300/1500, Mean Squared Error: 0.3252015614258443\n",
            "Epoch 400/1500, Mean Squared Error: 0.325146162247291\n",
            "Epoch 500/1500, Mean Squared Error: 0.3251141846456181\n",
            "Epoch 600/1500, Mean Squared Error: 0.3250934531601078\n",
            "Epoch 700/1500, Mean Squared Error: 0.32507896689218274\n",
            "Epoch 800/1500, Mean Squared Error: 0.32506829767740986\n",
            "Epoch 900/1500, Mean Squared Error: 0.32506012635483006\n",
            "Epoch 1000/1500, Mean Squared Error: 0.32505367577063277\n",
            "Epoch 1100/1500, Mean Squared Error: 0.32504845907567187\n",
            "Epoch 1200/1500, Mean Squared Error: 0.3250441561838758\n",
            "Epoch 1300/1500, Mean Squared Error: 0.32504054825955675\n",
            "Epoch 1400/1500, Mean Squared Error: 0.3250374807718628\n",
            "Epoch 1500/1500, Mean Squared Error: 0.32503484158612417\n",
            "Accuracy: 90.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kg5gP6alcpTS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}